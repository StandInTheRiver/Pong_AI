Steps,Policy/Entropy,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward
10000,1.0883415,-0.033772196527660385,36.351351351351354,-1.334938,-0.03416666825475215
20000,1.0831387,0.07492971431036977,31.099041533546327,-1.1899532,0.07490763965709384
30000,1.0787263,0.003970263753481015,36.468401486988846,-0.89625627,0.007563430383287148
40000,1.0765102,-0.03274822383970419,33.326241134751776,-0.6142277,-0.033560285336463484
50000,1.0745685,0.06305842318402481,32.797250859106526,-0.5028552,0.060342463830562486
60000,1.0657151,0.06429152986966073,33.85084745762712,-0.48276177,0.06765646329244637
70000,1.0672488,0.02695937845019216,30.0,-0.27362448,0.023993765060192213
80000,1.0669568,-0.0446137683424251,28.407185628742514,-0.20601565,-0.04799399731048682
