Steps,Policy/Entropy,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Extrinsic Reward
10000,1.0901979,0.5320267203110199,35.908396946564885,-1.5050752,0.5339693449659744
20000,1.0908141,0.5122979477068652,33.12328767123287,-1.2433898,0.5106348064159911
30000,1.0887835,0.5479773617911873,37.08301886792453,-0.9794947,0.549920451455612
40000,1.0810381,0.5629965329333371,32.888888888888886,-0.5950171,0.5615208296929066
50000,1.0645888,0.548530914679339,35.30909090909091,-0.4386211,0.5447846697010338
60000,1.0484359,0.5167122340946217,34.81294964028777,-0.33922797,0.5202892824242423
70000,1.0450221,0.5070741960767566,31.370967741935484,0.8467243,0.5085695745403845
80000,1.0538805,0.546056718768816,28.844776119402987,1.0442457,0.5445654703556405
